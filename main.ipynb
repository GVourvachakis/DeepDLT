{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[<img src=\\\"https://colab.research.google.com/img/colab_favicon.ico\\\" alt=\\\"Open this notebook in Google Colab\\\" width=\\\"80\\\">](https://colab.research.google.com/github/GVourvachakis/DeepDLT/blob/main/main.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customed Components\n",
    "\n",
    "### create_dataset.py \n",
    "Creates directory \"./dataset\" of **cropped and brightness-varying (by $\\pm$ 20%) 64x64 images** (create_dataset() function) in BMP (bitmap) format for storage efficiency and their respective **csv files** (create_data_with_labels_csv() function) splitted as training, validation, and testing datasets sampled from the excel file \"./images/all_images.xlsx\".\n",
    "\n",
    "### dataset_loader.py\n",
    "Construct flexible/modular **custom dataset class** LaserDataset(Dataset) with Ordinal encoded \"PP1\" categorical feature and respective train/val/test dataloaders (prepare_and_load_data() function) .\n",
    "\n",
    "### stratified_split.py\n",
    "Contains a subroutine for k-fold label-wise cross-validation splitting (k_fold_cross_validation() function, with fold=5 as default) and the main execution/development of the folds under a multil-label cross-validation() splitting scheme (main_cross_validation() function) .\n",
    "\n",
    "### environment.yml\n",
    "contains all the dependencies and requirements.\n",
    "\n",
    "### main.ipynb\n",
    "Notebook where the whole training and inferencing pipeline is implemented \n",
    "\n",
    "### KFold_split.py\n",
    "Creates DataLoader instances for 5-fold cross-validation . [optional]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect into the custom virtual environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/georgios-vourvachakis/Desktop/DeepDLT/pytorch_venv'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import os\n",
    "# !source pytorch_venv/bin/activate\n",
    "# os.environ['VIRTUAL_ENV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import native python and torch dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np ; import matplotlib; import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "import tqdm\n",
    "import torch ; import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import quantitative reconstruction evaluation metrics via scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage as ski\n",
    "print(ski.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python --version\n",
    "print(f\" matplotlib:\\t{matplotlib.__version__}\\n numpy:\\t\\t{np.__version__}\\\n",
    "      \\n pandas:\\t{pd.__version__}\\n tqdm:\\t\\t{tqdm.__version__}\\\n",
    "      \\n torch:\\t\\t{torch.__version__}\\n torchvision:\\t{torchvision.__version__}\\\n",
    "      \\n skimage:\\t{ski.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import custom dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_loader import LaserDataset, prepare_and_load_data\n",
    "from create_dataset import create_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct directory of augmented images along with train/val/test csv datasets\n",
    "(given the directory \"./datasets\" doesn't exist already)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not os.path.exists(\"./datasets\"):\n",
    "#     subprocess.run([\"python\", \"create_dataset.py\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate uniform label distribution-aware 5-fold cross-validation data (better *generalization*, acounting for *outliers*, and preventing *overfitting*) [given there are train/val/test files to sample from]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if os.path.exists(\"./datasets/data_with_labels_csv\"):\n",
    "#     subprocess.run([\"python\", \"stratified_split.py\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Complete preprocessing pipeline**:\n",
    "create_dataset , data_with_labels_csv and globally create train/val/test Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating dataset with cropped images...\n",
      "\n",
      "Creating csv files with (train_ratio, val_ratio, test_ratio) = (0.8, 0.1, 0.1)\n",
      "\n",
      "Creating DataLoaders...\n",
      "\n",
      "Training DataLoader...\n",
      "Validation DataLoader...\n",
      "Testing DataLoader...\n"
     ]
    }
   ],
   "source": [
    "# Define paths\n",
    "input_dirs = [\n",
    "                '2020-4-30 tuning ripple period',\n",
    "                '2020-6-9 Crossed polarized',\n",
    "                'Paper Data/Double pulses',\n",
    "                'Paper Data/Repetition 6p & 2p 29-4-2020',\n",
    "                'Paper Data/Single pulses 2p',\n",
    "                'Paper Data/Single pulses 4 and half 6',\n",
    "                'Paper Data/Repetition 6p & 2p 29-4-2020/Details'\n",
    "             ]\n",
    "    \n",
    "base_path = \"./images\"\n",
    "excel_path = \"./images/all_images.xlsx\" # sample data for train/val/test csv files\n",
    "csv_output_path = \"./datasets/data_with_labels_csv\"\n",
    "\n",
    "dim = 64 # set dimensions of augmented images\n",
    "\n",
    "images_path = f'./datasets/2023_im_dataset_{dim}x{dim}'\n",
    "output_dir_images = create_dir(images_path)\n",
    "\n",
    "train_loader, val_loader, test_loader = prepare_and_load_data(\n",
    "                                                                input_dirs,\n",
    "                                                                base_path,\n",
    "                                                                output_dir_images,\n",
    "                                                                excel_path,\n",
    "                                                                csv_output_path,\n",
    "                                                                cropped_dim=dim\n",
    "                                                             )   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model initialization from models directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CNNAutoencoder is exposed in __init__.py\n",
    "\n",
    "#Directory tructure:\n",
    "# DeepDLT/\n",
    "# ├── models/\n",
    "# │   ├── __init__.py\n",
    "# │   └── autoencoder.py\n",
    "# └── autoencoder.ipynb.py\n",
    "\n",
    "from models.autoencoder import CNNAutoencoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training_pipeline import train_model, load_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using {device}\")\n",
    "\n",
    "# Data Preparation (embedded into the LaserDataset class)\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=(0.5,), std=(0.5,))\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Initialization\n",
    "model = CNNAutoencoder(activation_function='relu', dropout_strength=0.3).to(device)\n",
    "\n",
    "learning_rate = 1e-3\n",
    "optimizer = 'Adam'\n",
    "epochs = 100\n",
    "\n",
    "# Train the model\n",
    "train_losses, val_losses, psnr_values, ssim_values = train_model(model, train_loader, val_loader, device,\n",
    "                                                                 optimizer=optimizer, num_epochs=epochs//2, learning_rate=learning_rate,\n",
    "                                                                 checkpoint_name='model_checkpoint', # saving a checkpoint model every 10 epochs\n",
    "                                                                 best_metric_checkpoint_name='best_model') # saving best models for loss, psnr, and ssim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Checkpoint for Inference and/or Resuming Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load checkpoint\n",
    "file_path =  f'./models_history_{optimizer}/model_checkpoint.pt'\n",
    "\n",
    "model, optimizer, start_epoch, loss = load_checkpoint(model, optimizer, file_path, lr=learning_rate)\n",
    "\n",
    "# Set model to eval mode for evaluation or train mode to continue training\n",
    "model.eval()  # For evaluation\n",
    "# Or:\n",
    "# model.train()  # For resuming training\n",
    "\n",
    "print(f\"Model restored to epoch {start_epoch} with loss {loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue Training the model\n",
    "train_losses, val_losses, psnr_values, ssim_values = train_model(model, train_loader, val_loader, device,\n",
    "                                                                 optimizer='Adam', start_epoch=start_epoch, num_epochs=epochs, learning_rate=1e-2,\n",
    "                                                                 checkpoint_name='model_checkpoint', \n",
    "                                                                 best_metric_checkpoint_name='best_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain the loss curves, and PSNR and SSIM values accross epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference import plotting, visualize_reconstruction\n",
    "\n",
    "plotting(train_losses=train_losses, val_losses=val_losses, psnr_values=psnr_values, ssim_values=ssim_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize Reconstruction on Training and Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruction on Training Data\n",
    "print(\"Reconstruction on Training Data:\")\n",
    "visualize_reconstruction(train_loader, model, device, num_images=5)\n",
    "\n",
    "# Reconstruction on Test Data\n",
    "print(\"Reconstruction on Test Data:\")\n",
    "visualize_reconstruction(test_loader, model, device, num_images=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "if os.path.exists(\"./datasets/data_with_labels_csv\"):\n",
    "    subprocess.run([\"python\", \"stratified_split.py\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "def train_and_evaluate_kfold(model_class, fold_dir, num_folds, device, features , criterion=nn.MSELoss(), num_epochs=10, learning_rate=1e-3):\n",
    "    fold_train_losses = []\n",
    "    fold_val_losses = []\n",
    "    fold_test_losses = []\n",
    "\n",
    "    print(f\"Procedure must be done across ALL features: {features}, now it is operated only on {features[0]}...\\n\")\n",
    "\n",
    "    for fold in range(1, num_folds + 1):\n",
    "        print(f\"Starting Fold {fold}/{num_folds}...\")\n",
    "        \n",
    "        # Asoociate appropriate path for the fold's datasets\n",
    "        train_path = os.path.join(fold_dir, 'angle', f'fold_{fold}', 'angle_train.csv')\n",
    "        val_path = os.path.join(fold_dir, 'angle', f'fold_{fold}', 'angle_val.csv')\n",
    "        test_path = os.path.join(fold_dir, 'angle', f'fold_{fold}', 'angle_test.csv')\n",
    "\n",
    "        # Load the datasets for the current fold\n",
    "        train_dataset = LaserDataset(train_path, transform=transform)\n",
    "        val_dataset = LaserDataset(val_path, transform=transform)\n",
    "        test_dataset = LaserDataset(test_path, transform=transform)\n",
    "\n",
    "        # Prepare Dataloaders\n",
    "        train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "        # Initialize the model for this fold\n",
    "        model = model_class(activation_function='relu', dropout_strength=0.2).to(device)\n",
    "\n",
    "        # Train the model\n",
    "        train_losses, val_losses = train_model(model, train_loader, val_loader, device, criterion=criterion, num_epochs=num_epochs, learning_rate=learning_rate) \n",
    "\n",
    "        # Evaluate the model on the test set\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        all_outputs = []\n",
    "        all_targets = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, _ in tqdm(test_loader, desc=f\"Testing Fold {fold}/{num_folds}\"):\n",
    "                inputs = inputs.to(device)\n",
    "                outputs = model(inputs)\n",
    "                test_loss += criterion(inputs, outputs) * inputs.size(0)\n",
    "                all_outputs.extend(outputs.cpu().numpy())\n",
    "                all_targets.extend(inputs.cpu().numpy())\n",
    "\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        fold_test_losses.append(test_loss)\n",
    "\n",
    "        # Log fold results\n",
    "        print(f\"Fold {fold}/{num_folds} - Train Loss: {train_losses[-1]:.4f}, Val Loss: {val_losses[-1]:.4f}, Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "        # Store fold-wise losses\n",
    "        fold_train_losses.append(train_losses)\n",
    "        fold_val_losses.append(val_losses)\n",
    "\n",
    "        # Visualize reconstruction\n",
    "        print(f\"Visualizing Reconstruction for Fold {fold}...\")\n",
    "        visualize_reconstruction(test_loader, model, device, num_images=5)\n",
    "\n",
    "    # Average Test Loss across all folds\n",
    "    avg_test_loss = sum(fold_test_losses) / num_folds\n",
    "    print(f\"Average Test Loss across all folds for 'angle' feature: {avg_test_loss:.4f}\")\n",
    "\n",
    "    return fold_train_losses, fold_val_losses, fold_test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Stratified splits path\n",
    "stratified_dir = \"./datasets/uniform_cross_validation_data\"\n",
    "num_folds = 3\n",
    "\n",
    "labels = ['angle', 'EP1', 'NP', 'PP1']\n",
    "\n",
    "# Train and evaluate the model across all folds\n",
    "train_and_evaluate_kfold(CNNAutoencoder, stratified_dir, num_folds, device, features=labels , num_epochs=1, learning_rate=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
